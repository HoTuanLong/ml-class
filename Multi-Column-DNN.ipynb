{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict\n",
    "from tqdm import tqdm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create function to generate dataset at specific size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datasets(target_size=29):\n",
    "    assert target_size <= 29 and target_size % 2 == 1\n",
    "    dataset_transforms = transforms.Compose([\n",
    "        transforms.Resize((target_size, target_size)),\n",
    "        transforms.Pad( (29-target_size) // 2 ),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "    train_dataset = datasets.MNIST('./data', train=True, transform=dataset_transforms, target_transform=None, download=True)\n",
    "    \n",
    "    train_size = int(0.8 * len(train_dataset))\n",
    "    valid_size = len(train_dataset) - train_size\n",
    "    \n",
    "    torch.manual_seed(42) # keep same seed everytime\n",
    "    train_dataset, valid_dataset = random_split(train_dataset, [train_size, valid_size])\n",
    "    test_dataset = datasets.MNIST('./data', train=False, transform=dataset_transforms, target_transform=None, download=True)\n",
    "    return dict(train=train_dataset, valid=valid_dataset, test=test_dataset)\n",
    "\n",
    "def show_tensor_image(image):\n",
    "    plt.imshow(transforms.ToPILImage()(image), cmap='gray');\n",
    "    \n",
    "def get_dataloaders(data):\n",
    "    dataloaders = dict(\n",
    "        train=DataLoader(data['train'], batch_size=32, shuffle=True, num_workers=6),\n",
    "        valid=DataLoader(data['valid'], batch_size=32, shuffle=False, num_workers=6),\n",
    "        test=DataLoader(data['test'], batch_size=32, shuffle=False, num_workers=6),\n",
    "    )\n",
    "    return dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48000, 10000)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = get_datasets(target_size=21)\n",
    "len(data['train']), len(data['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Tensor, int, torch.Size([1, 29, 29]))"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = data['train'][0]\n",
    "type(x), type(y), x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_tensor_image(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create model class and get_model function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first layer torch.Size([32, 20, 26, 26])\n",
      "second layer torch.Size([32, 20, 13, 13])\n",
      "third layer torch.Size([32, 40, 9, 9])\n",
      "fourth layer torch.Size([32, 40, 3, 3])\n",
      "final layer torch.Size([32, 10])\n"
     ]
    }
   ],
   "source": [
    "class MCDNN1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MCDNN1, self).__init__()\n",
    "        self.net = nn.Sequential(OrderedDict([\n",
    "            ('conv1', nn.Conv2d(in_channels=1, out_channels=20, kernel_size=4)),\n",
    "            ('relu1', nn.ReLU()),\n",
    "        ]))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = x\n",
    "        out = self.net(out)\n",
    "        return out\n",
    "\n",
    "class MCDNN2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MCDNN2, self).__init__()\n",
    "        self.net = nn.Sequential(OrderedDict([\n",
    "            ('conv1', nn.Conv2d(in_channels=1, out_channels=20, kernel_size=4)),\n",
    "            ('relu1', nn.ReLU()),\n",
    "            ('pool1', nn.MaxPool2d(kernel_size=2)),\n",
    "        ]))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = x\n",
    "        out = self.net(out)\n",
    "        return out\n",
    "\n",
    "class MCDNN3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MCDNN3, self).__init__()\n",
    "        self.net = nn.Sequential(OrderedDict([\n",
    "            ('conv1', nn.Conv2d(in_channels=1, out_channels=20, kernel_size=4)),\n",
    "            ('relu1', nn.ReLU()),\n",
    "            ('pool1', nn.MaxPool2d(kernel_size=2)),\n",
    "            ('conv2', nn.Conv2d(in_channels=20, out_channels=40, kernel_size=5)),\n",
    "            ('relu2', nn.ReLU()),\n",
    "        ]))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = x\n",
    "        out = self.net(out)\n",
    "        return out\n",
    "\n",
    "class MCDNN4(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MCDNN4, self).__init__()\n",
    "        self.net = nn.Sequential(OrderedDict([\n",
    "            ('conv1', nn.Conv2d(in_channels=1, out_channels=20, kernel_size=4)),\n",
    "            ('relu1', nn.ReLU()),\n",
    "            ('pool1', nn.MaxPool2d(kernel_size=2)),\n",
    "            ('conv2', nn.Conv2d(in_channels=20, out_channels=40, kernel_size=5)),\n",
    "            ('relu2', nn.ReLU()),\n",
    "            ('pool2', nn.MaxPool2d(kernel_size=3)),\n",
    "        ]))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = x\n",
    "        out = self.net(out)\n",
    "        return out\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Flatten, self).__init__()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return torch.flatten(x, start_dim=1)\n",
    "    \n",
    "class MCDNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MCDNN, self).__init__()\n",
    "        self.net = nn.Sequential(OrderedDict([\n",
    "            ('conv1', nn.Conv2d(in_channels=1, out_channels=20, kernel_size=4)),\n",
    "            ('relu1', nn.ReLU()),\n",
    "            ('pool1', nn.MaxPool2d(kernel_size=2)),\n",
    "            ('conv2', nn.Conv2d(in_channels=20, out_channels=40, kernel_size=5)),\n",
    "            ('relu2', nn.ReLU()),\n",
    "            ('pool2', nn.MaxPool2d(kernel_size=3)),\n",
    "            ('flatten', Flatten()),\n",
    "            ('fc1', nn.Linear(in_features=40*3*3, out_features=150)),\n",
    "            ('relu3', nn.ReLU()),\n",
    "            ('fc2', nn.Linear(in_features=150, out_features=10)),\n",
    "        ]))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = x\n",
    "        out = self.net(out)\n",
    "        return out\n",
    "\n",
    "data = get_datasets(target_size=21)\n",
    "dataloaders = get_dataloaders(data)\n",
    "batch_x, batch_y = next(iter(dataloaders['train']))\n",
    "print('first layer', MCDNN1()(batch_x).shape)\n",
    "print('second layer', MCDNN2()(batch_x).shape)\n",
    "print('third layer', MCDNN3()(batch_x).shape)\n",
    "print('fourth layer', MCDNN4()(batch_x).shape)\n",
    "print('final layer', MCDNN()(batch_x).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create training function to train a model given ```dataloaders['train']``` and ```dataloaders['valid']```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 0 new best 0.076 saved to ./models/model_29_0.pth: 100%|██████████| 1/1 [00:13<00:00, 13.00s/it]\n"
     ]
    }
   ],
   "source": [
    "def train_model(dataloaders, model, loss_func, optimizer, scheduler=None, device=\"cuda:0\", epochs=1, save_func=None):\n",
    "    \n",
    "    def train_epoch():\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for batch_x, batch_y in dataloaders['train']:\n",
    "            batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "            pred = model(batch_x)\n",
    "            loss = loss_func(pred, batch_y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if scheduler is not None: scheduler.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "        return total_loss / len(dataloaders['train'])\n",
    "            \n",
    "    def valid_epoch():\n",
    "        model.eval()\n",
    "        total_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for batch_x, batch_y in dataloaders['valid']:\n",
    "                batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "                pred = model(batch_x)\n",
    "                loss = loss_func(pred, batch_y)\n",
    "                total_loss += loss.item()\n",
    "        return total_loss / len(dataloaders['valid'])\n",
    "    \n",
    "    train_loss, valid_loss = [], []\n",
    "    best_valid_loss = float('inf')\n",
    "    pbar = tqdm(range(epochs), total=epochs)\n",
    "    for epoch in pbar:\n",
    "        train_loss.append(train_epoch())\n",
    "        valid_loss.append(valid_epoch())\n",
    "        pbar.set_description(f'epoch {epoch} current best {best_valid_loss:.3f}')\n",
    "        if save_func is not None:\n",
    "            if valid_loss[-1] < best_valid_loss:\n",
    "                save_message = save_func(model)\n",
    "                best_valid_loss = valid_loss[-1]\n",
    "                pbar.set_description(f'epoch {epoch} new best {valid_loss[-1]:.3f} {save_message}')\n",
    "    return train_loss, valid_loss\n",
    "                \n",
    "def save_func(target_size, column):\n",
    "                \n",
    "    def __save_func(model):\n",
    "        model_path = f'./models/model_{target_size}_{column}.pth'\n",
    "        torch.save(dict(state_dict=model.state_dict()), model_path)\n",
    "        return f'saved to {model_path}'\n",
    "    \n",
    "    return __save_func\n",
    "\n",
    "data = get_datasets(target_size=29)\n",
    "dataloaders = get_dataloaders(data)\n",
    "\n",
    "device = \"cuda:0\"\n",
    "epochs = 1\n",
    "model = MCDNN().to(device)\n",
    "loss_func = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), weight_decay=1e-4)\n",
    "train_model(dataloaders, model, loss_func, optimizer, epochs=epochs, device=device, save_func=save_func(29, 0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train all models and save best models to ```./models``` folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 9 current best 0.034389876435200376: 100%|██████████| 10/10 [02:09<00:00, 12.98s/it]             \n",
      "epoch 9 current best 0.032259031047423684: 100%|██████████| 10/10 [02:10<00:00, 13.06s/it]             \n",
      "epoch 9 current best 0.03366647850970427: 100%|██████████| 10/10 [02:07<00:00, 12.76s/it]              \n",
      "epoch 9 current best 0.03287554679314295: 100%|██████████| 10/10 [02:08<00:00, 12.85s/it]              \n",
      "epoch 9 current best 0.03118568988641103: 100%|██████████| 10/10 [02:07<00:00, 12.78s/it]              \n",
      "epoch 9 current best 0.034750110864639285: 100%|██████████| 10/10 [02:09<00:00, 12.92s/it]             \n",
      "epoch 3 current best 0.04043356861670812:  40%|████      | 4/10 [00:53<01:20, 13.34s/it]               "
     ]
    }
   ],
   "source": [
    "for target_size in [29, 27, 25, 21, 17, 13, 11]:\n",
    "    for column in range(5):\n",
    "        data = get_datasets(target_size=target_size)\n",
    "        dataloaders = get_dataloaders(data)\n",
    "\n",
    "        device = \"cuda:0\"\n",
    "        epochs = 10\n",
    "        model = MCDNN().to(device)\n",
    "        loss_func = torch.nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), weight_decay=1e-4)\n",
    "        train_model(dataloaders, model, loss_func, optimizer, epochs=epochs, device=device, save_func=save_func(target_size, column))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
